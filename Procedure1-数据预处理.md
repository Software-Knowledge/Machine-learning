Procedure1-数据预处理
---
> 由于数据预处理的重要性，作为机器学习流程的重要一环，单独拿出来进行讨论。

# 1. 数据质量要求
1. 数据质量要求数据是完整的和真实的，并且具有一致性和可靠性。
2. 数据预处理可以占到整个机器学习项目的60%及以上的工作量。

# 2. 数据预处理面临的问题与解决方案

## 2.1. 数据采样不均衡
> 数据采样得到的样本中不同类别的数据量并不均衡。

1. 需要考虑采样得到的数据的多样性和高效性。
2. 需要考虑相应的采样标准

## 2.2. 数据总量

### 2.2.1. 数据总量不足
> 数据量总量不足，拟合困难，某一类别的样本很少

1. 我们希望有足量的、覆盖面尽可能广、多维度(覆盖与分析目标相关的维度)的样本数据用于机器学习。数据量增多，其中的规律相对更加明显，更易于发现与分析目标相关的因素。
2. 数据量可以补充：搜集或者使用爬虫来获取更多的数据
3. 数据量无法补充：机器仿真产生
4. 合适的数据量：数据量是自变量的10-20倍为好，但是根据不同机器学习算法有不同的敏感度。
  
### 2.2.2. 数据总量过多
> 数据量总量过多，比如有重读的数据，加重了工作量，影响部分机器学习算法情况

1. 我们需要检查数据的覆盖性是否好、硬件的配置是否达标
2. 对于海量的同质化数据，我们可以通过聚集技术按照时间、空间等属性进行均值等部分的汇总，减少数据数量。
3. 数据不平衡的问题可能会导致出现较大的结果误差，因此要对数据集应用采样技术或对异常数据进行赋值，提高其占比。

## 2.3. 数据的维度较高
> 数据的维度是很高的，我们需要通过一些降维方法来降低数据维度。

1. 维度灾难:描述一个问题的角度十分多，高清大图的维度很高，但是比较高的维度未必是必要的。
2. 当数据中的自变量变多的时候，会出现维度灾难等问题，尤其是在矩阵数据中，其中冗余变量占比较高的时候，可用数据变成稀疏网络。
3. 可以通过线性代数的方法将数据从高维空间映射到低维空间
  1. 主成分分析
  2. 奇异值分解

## 2.4. 数据不完整
> 数据没有填写部分的数据项，数据不完整或缺失

1. 数据的种类不够：可以编写程序从外部抓取数据作为补充。
2. 数据缺失：数据不完整的一种表现，针对不同显示情况来进行人为处理
   1. 利用众数、中位数、均值、最短距离等方式完成人为补充。
   2. 通过回归或贝叶斯定律等方式来预测缺失值
   3. 删除含有缺失值的数据

## 2.5. 数据异常
> 异常数据：错误值或者离群值等

1. 分为错误的数据和小概率出现的数据
2. 对于错误的数据，我们需要识别、剔除或修正
3. 对于小概率出现的数据
   1. 我们需要重点分析特征，比如信用卡欺诈、垃圾邮件等。
   2. 如何识别是小概率出现还是巧合：多次试验可以避免巧合。

## 2.6. 数据的时效性
> 数据的时效性问题：关注部分问题下的数据的时效性

# 3. 常见数据预处理操作

## 3.1. 数据收集
> 收集相关的数据

1. 来源上划分
   1. 内部业务系统的数据
   2. 外部数据：可以通过网络爬虫、购买或交易方式获取
2. 特点上划分
   1. 非结构化数据
   2. 半结构化数据
   3. 结构化数据

## 3.2. 数据的相关性识别
1. 虽然y和x不成线性关系，但是y和x的多项式可能满足线性关系：这就使得我们可以对数据进行专门的预处理。
2. 除了线性关系，还有对数关系和指数关系怎么处理呢？
   1. 对数关系：麦克劳林展开
   2. 指数关系：泰勒展开

## 3.3. 特征缩放
1. 特征缩放，又称属性缩放，通过调整所有属性保证其取值范围大致相同，有效地加快和保证了梯度下降的速度。
2. 常用的数据缩放范围是(-1, 1)：你还可以发现属于这个范围的数的任意次幂都属于这个范围。

## 3.4. 数据归一化
1. 不同数据不可以直接比较，可能出现不同的比例的比较的情况
2. 我们需要将数据进行归一化后进行处理
3. 结合特征缩放和数据归一化，我们得到如下公式(其中m是总样本数)

$$
x_i = \frac{x_i = \frac{\sum\limits_1\limits^mx_j}{m}}{\max(|x_k|)}
$$