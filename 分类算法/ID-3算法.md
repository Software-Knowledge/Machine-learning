# 1. ID3算法
1. 最简答机器学习算法，使用了启发式算法来进行决策树的构造。例如，使用贪婪算法对每个结点构造部分最优决策树。
2. 算法内容:每次使用一个最有区分力的属性来看是否能把各个数据分类分开。
3. 算法精髓:在于分支处理，即确定在每个决策结点出的分支属性。
    + 分支属性的选取即对决策节点上选择哪一个属性来对数据集进行划分，要求每个分支中样本的类别纯度尽可能高，而且不要产生样本数量太少的分支。

## 1.1. 具体算法实现
![](img\ID3\ID3-1.png)

1. 问题一:如何选择出有区分度的属性？ID3使用了信息增益的概念。
2. 算法描述:按照递归来寻找有区分度的属性。算法需要获得相应可以减少不确定的因素。
    + 哪个因素考虑和不考察了之差最大就可以选择这个因素。
    + 他的符号有相应意义
3. 公式描述:
    1. 通过频率代替概率
4. 算法输入是一个决策表，最后一列是导致信号(示范)。

![](img\ID3\ID3-2.png)

1. 他的物理含义就是两个熵之差，也就是考虑A的熵减去不考虑A的熵。
2. 我需要依次计算每一个因素的，而公式中第一个熵是不考虑任何其他因素的情况下的，后面的是考虑A后的熵

## 1.2. 例子

![](img\ID3\ID3-3.png)

1. 不考虑任何因素，直接按照导致信号进行计算熵。也是所有情况的熵和。
2. 然后从其他属性中找到一个属性来进行计算，在A条件下，是导致信号的数量。(计算条件熵)
    + 比如在非A条件下，分别计数是导致信号的有几个，不是的有几个。如果相应比例大的话，当然可以降低不确定性因素。(在第二种情况下，比如在A条件下，重复上述操作。)
3. 然后计算整个样本的情况的熵和来作为公式第二项。
4. 结果:比较保留最大值。


饮食习性为分类
---
![](img\ID3\ID3-4.png)
---
![](img\ID3\ID3-5.png)
---
![](img\ID3\ID3-6.png)
全部结果
---
![](img\ID3\ID3-7.png)

5. 将胎生动物作为根节点，然后按照情况画分支，分开样本集，然后相应分支再继续向下分(递归)。
    + 当分支下到全是同一类的就不用再进行分支了。
    
![](img\ID3\ID3-8.png)

## 1.3. 算法总结

![](img\ID3\ID3-9.png)

1. CSDN上的python实现ID3<a href = "https://blog.csdn.net/weixin_38273255/article/details/88981748">详见</a>