**决策树与分类算法**
1. 分类的任务是将样本(对象)划分到合适的预定义目标类中

# 1. 决策树是什么
1. 决策树是一个树状结构，用来辅助我们进行决策

# 2. 决策树算法
1. 分类算法是利用训练样本集获得分类函数即分类模型(分类器)，从而实现将数据集中的样本划分到各个类中。分类模型通过学习训练样本中属性集与类别之间的潜在关系，并以此为依据对新样本属于哪一类进行预测
2. 决策树算法模拟人的是识别能力

## 2.1. 决策树算法思想
1. 决策树通过把数据样本分配到某个叶子结点来确定数据集中样本所属的分类 
2. 决策树的组成:决策结点、分支和叶子结点
    1. 决策结点表示在样本的一个属性上进行的划分 
    2. 分支表示对于决策结点进行划分的输出,用椭圆表示 
    3. 叶结点代表经过分支到达的类，用长方形表示
3. 从决策树根结点出发，自顶向下移动，在每个决策结点都会进行次划分，通过划分的结果将样本进行分类，导致不同的分支，最后到达个叶子结点，这个过程就是利用决策树进行分类的过程.
4. 抽离出事物的最本质特征，作为特征点来进行分类。

## 2.2. GBDT
1. 决策树一般分为回归树与分类树:
    1. 分类树的结果不能进行加减运算。
    2. 回归树的结果是数值，可以进行加减运算，如年龄、身高等。
    3. GBDT中的决策树是回归树。
    4. 通过损失函数:最大熵VS均方差来评估模型的准确率。
2. 如果在不改变原有模型的结构的基础上提升模型的拟合能力?
    + 可以优化模型。
    + 也可以增加一个新的模型，拟合其残差。比如(170+10=180)

![](img\GBDT\GBDT-1.png)

第一个F(x)是均方差，第二个是差等于负梯度方向，作为残差的估计值。对于负梯度直接求导是一个比较快速的方法。

### 2.2.1. 思路分析
1. 利用梯度下降，用损失函数的负梯度在当前模型的值，作为提升树中**残差**的近似值来**拟合回归决策树**，算法过程如下:
    1. 初识化决策树，估计一个使损失函数最小化的常数构建一个只有根节点的树。
    2. 不断提升迭代:
        1. 计算当前模型中损失函数的负梯度值，作为残差的估计值。
        2. 估计回归树中叶子节点的区域，拟合残差的近似值。
        3. 利用线性搜索估计叶节点区域的值，使损失函数极小化。
        4. 更新决策树。
    3. 经过若干论的提升法迭代过程之后，输出最终的模型.
![](img\GBDT\GBDT-2.png)

1. 多个基模型作为基础，来进行一步一步拟合决策树
2. 最后一个公式是每个的固定值的损失+正则部分(最终的损失函数)

### 2.2.2. XGBoost树提升系统
1. 对于GBDT算法的具体实现，最为出色的是XGBoost树提升系统。
2. 下面是在Python环境下使用XGBoost模块进行回归的调用示例，首先用 pandas构造一个最简单的数据集df，其中x的值为[1,2,3]，y的值为[10,20,30] ，并构建训练集矩阵T_train_xbg。
3. 代码如下:
```python
import pandas as pd
import xgboost as xgb
df = pd.DataFrame({'x':[1,2,3], 'y':[10,20,30]})
X_train = df.drop('y',axis=1)
Y_train = df['y']
T_train_xgb = xgb.DMatrix(X_train, Y_train)
params = {"objective": "reg:linear", "booster":"gblinear"}# reg线性回归，booster使用gb线性回归
gbm = xgb.train(dtrain=T_train_xgb,params=params)# 进行训练
Y_pred = gbm.predict(xgb.DMatrix(pd.DataFrame({'x':[4,5]}))) print(Y_pred)#输入一个x的一个值，就可以输出一个y的值。
```

### 2.2.3. GBDT特点

![](img\GBDT\GBDT-3.png)

1. 超参比较多:交叉验证、grad_search进行自动化调参。
2. 不用正则化、归一化等问题的处理。
3. Boost是串行过程，按照线性序列顺序做，很难进行并行处理。
    + 可以通过PC降维处理来完成使用
4. 平方损失:用绝对损失，我的预测值和之前的模型的差不进行平方，减少异常值造成的损失，而Huber损失是均衡进行，根据阈值进行比较。
    + 减去阈值/2->调整因子
5. 其他可以看官网手册。

### 2.2.4. 推荐系统
1. 假设推荐10个，每一个曾喜欢的东西会有差值。