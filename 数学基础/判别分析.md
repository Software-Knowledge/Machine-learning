**判别分析**

# 1. 判别分析目标
1. 判别分析是利用已知类型的样本建立判别模型，对未知类型的样本进行判别的一种统计方法。
2. 核心:总结客观事物分类的**规律性**，建立判别公式和**判别准则**
3. 目标一(分类):在已知判别模型的情况下，判定新样本应该归属的**类别**
4. 目标二(描述):最大化各类别之间的差异性，最大限度地分离各类别，一般用降维方法或代数方法。

# 2. 判别分析类别

## 2.1. 按判别的类数
1. 二分类判别分析
2. 多分类判别分析

## 2.2. 按所含变量个数
1. 一元判别分析
2. 多元判别分析

## 2.3. 按判别准则分 

### 2.3.1. 距离
1. 计算每个分类的中心坐标，然后对新样本求出他们离各个类别中心的距离的远近，从而归入离的最近的分类
2. 如:马氏距离(协方差距离)，欧氏距离，分类。
    + 马氏距离不关心具体的问题

### 2.3.2. 费歇(fisher)(LDA)
1. 投影，将高维空间的自变量组合投影到维度较低维空间去，然后在低维空间中进行分类。
2. 投影原则:使类内的离差尽可能的笑，不同类见投影的离差尽可能大。
3. 应用:分类+**分离**
    + 更倾向于数据描述

### 2.3.3. 贝叶斯(BAYES)
1. 在考虑先验概率的前提下，利用贝叶斯公式，按照一定准则构造一个判别函数，计算样本落入各个子域的概率。
2. 应用:分类

# 3. 具体判别分析

## 3.1. 线性判别分析(LDA)

### 3.1.1. 什么是LDA
1. 线性判别分析LDA是一种有监督的线性降维算法。与PCA不同，LDA是为了使降维后的数据点尽可能地容易被区分。

### 3.1.2. LDA的原理
1. 线性判别分析的原理是对于给定的训练集，设法将样本投影到一条直线上，使得同类的投影点尽可能接近，异类样本的投影点尽可能远离；在对新样本进行分类时，将其投影到这条直线上，再根据投影点的位置来确定新样本的类别。PCA主要是从特征的协方差角度，去找到比较好的投影方式。LDA更多地考虑了标注，即希望投影后不同类别之间数据点的距离更大，同一类别的数据点更紧凑。

### 3.1.3. LDA的过程

![](img\LDA\3.png)

1. 转换到新的子空间后可分。
2. 右侧图:二维减低了一维的

### 3.1.4. 实例

![](img\LDA\4.png)

二次判别决策面运行效果比较
---
![](img\LDA\5.png)

1. LDA的部分可能会存在一定的错误分类。

### 3.1.5. LDA可视化和分析
1. 应用LDA技术对鸢尾花(Iris)的样本数据进行分析，鸢尾花数据集是20世纪30年代的经典数据集，它由Fisher收集整理，数据集包含150个数据集，分为3类，每类50个数据，每个数据包含4个属性。可通过花萼长度、花萼宽度、花瓣长度和花瓣宽度4个属性预测鸢尾花卉属于山鸢尾（Iris Setosa）、杂色 鸢尾（Iris Versicolour）、维吉尼亚鸢尾（Iris Virginica）中的哪种类别，将类别文字转化为数字类别
2. 情况图

![](img\LDA\6.png)

结果分析
---
![](img\LDA\7.png)

### 3.1.6. python实现

<a href ="https://blog.csdn.net/z962013489/article/details/79871789">详情</a>

## 3.2. 二次判别分析(QDA)

## 3.3. 如何选择不同判别分析的方法

![](img\LDA\1.png)

1. 复杂度高，样本数大，使用QDA
2. 选择主要取决于**方差和偏差**

![](img\LDA\2.png)

1. 过于灵敏=>过拟合
2. 高误差=>模型准确性比较迟钝
3. 误差(偏差)随时间减少，而方差随时间增大，其交点涉及到我们的取舍。