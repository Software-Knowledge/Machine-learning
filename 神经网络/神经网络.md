**神经网络**

# 1. 神经网络基础
1. 人工神经网络(Artificial Neural Netork,即ANN)是由简单神经元经过相互连接形成网状结构，通过调节各连接的**权重值**改变连接的强度，进而实现感知判断。
    + 从单个神经元到多个神经元
2. 反向传播(Back Propagation, BP) 算法的提出进一步推动了神经网络的发展。目前，神经网络作为一种重要的数据挖掘方法，已在医学诊断、信用卡欺诈识别、手写数字识别以及发动机的故障诊断等领域得到了广泛的应用。
    + 调优，如何求局部极小值，和一些问题。
3. 本章将介绍神经网络基本分类，包括前馈神经网络、反馈神经网络、自组织神经网络等常用的神经网络模型。重点介绍神经网络的概念和基本原理，为后续深度学习章节的学习打下基础。
4. 在神经网络中引入非线性？修正ReLU.

## 1.1. 传统神经网络
1. 传统神经网络结构比较简单，训练时随机初始化输入参数，并开启**循环计算**输出结果，与实际结果进行比较从而得到损失函数，并更新变量使损失函数结果值极小，当达到误差阈值时即可停止循环。
    + 最早的是单神经元的，并且连接结构简单。
    + 比较常用的是线性分类问题。
2. 神经网络的训练目的是希望能够学习到一个模型，实现输出一个期望的目标值。学习的方式是在**外界输入**样本的刺激下不断改变**网络的连接权值**。传统神经网络主要分为一下几类：前馈型神经网络，反馈型神经网络和自组织神经网络。
3. 这几类网络具有不同的学习训练算法，可以归结为监督型学习算法和非监督型学习算法。
4. 神经网络是之间隐式地获得相应的特征，而这个网络就是相应的特征值。

## 1.2. 神经元是如何建模的？
1. 感知器是一种结构最简单的前馈神经网络，也称为感知机，它主要用于求解分类问题
2. 一个感知器可以接收𝑛个输入𝑥=(𝑥1,𝑥2,…,𝑥𝑛)，对应𝑛个权值 𝑤=(𝑤1,𝑤2,…,𝑤𝑛)，此外还有一个偏置项阈值，就是图中的𝑏，神经元将所有输入参数与对应权值进行加权求和，得到的结果经过**激活函数**变换后输出，计算公式如下： 

![](img\intro\1.png)

1. SUM是核
2. 处理函数:f
3. 输入来自外界或者上一级神经元
4. SUM主要是进行加权和，公式中x和w都是向量，b是每个神经元的常数。
5. 注意:每个神经元是单一的，但是复杂的神经元是可以处理很多问题的。
6. 神经元可以有一个输入也可以有多个输入，可以有一个输出也可以有多个输出。、
    + 但是某一神经元可以连接下一层的多个神经元，表示该神经元有多个输出。

### 1.2.1. 感知器可以做的事情
1. 神经元的作用可以理解为对输入空间进行直线划分，单层感知机无法解决最简单的非线性可分问题----异或问题。
2. 感知器可以顺利求解与(AND)和或(OR)问题，但是对于异或(XOR)问题，单层感知机无法通过一条线进行分割。

![](img\intro\2.png)

1. 异或问题就很难线性完成了。是非线性可分的。

## 1.3. 前馈神经网络(Feed Forward Neural Network)
1. 前馈神经网络(Feed Forward Neural Network) 是一种单向多层的网络结构，即信息是从输入层开始，逐层向一个方向传递，一直到输出层结束。所谓的"前馈"是指输入信号的传播方向为前向，在此过程中并不调整各层的权值参数，而反传播时是将误差逐层向后传递，从而实现使用权值参数对特征的记忆，即通过反向传播(BP)算法来计算各层网络中神经元之间边的权重。BP算法具有非线性映射能力，理论上可逼近任意连续函，从而实现对模型的学习。
2. 主要是做分类。
3. <a href = "https://mp.weixin.qq.com/s/dOOwpsc5_0FHs93syG3SHw">从头开始解释前馈神经网络</a>

# 2. 神经网络相关概念
1.  学习神经网络相关概念有助于理解深度学习中网络设计原理，可在模型训练过程中有的放矢地调整参数，并且这些神经网络相关概念是深度学习的基础，随着深度学习的不断演化，深入理解这些常识性理论有助于快速理解层出不穷的深度学习网络模型。

## 2.1. 激活函数
1. 激活函数经常使用Sigmoid函数、tanh函数、ReLu函数
2. 激活函数通常有以下性质
    1. 非线性
    2. 可微性
    3. 单调性 𝑓(𝑥)≈ 𝑥
    4. 输出值范围:可控
    5. 计算简单
    6. 归一化
3. 通常我们使用ReLU函数，并设置好学习率
4.  如果存在死亡神经元的问题，就尝试Leaky ReLU或Maxout函数
5. 尽量避免使用Sigmoid函数
6. tahn函数大部分情况下效果不如ReLU和Maxout函数

### 2.1.1. Sigmoid函数

1. Sigmoid函数的优点在于输出范围有限，数据在传递的过程中不容易发散，并且其输出范围为(0,1)，可以在输出层表示概率值。Sigmoid函数的导数是非零的，很容易计算.
2. Sigmoid函数的主要缺点是**梯度下降非常明显**，且**两头过于平坦**，容易出现梯度消失的情况，输出的值域不对称，并非像tanh函数那样值域是-1到1。

![](img\intro\3.png)

### 2.1.2. tanh函数(双曲正切)
1. 双曲正切函数将数据映射到[-1,1]，解决了Sigmoid函数输出值域不对称问题。另外，它是完全可微分和反对称的，对称中心在原点。然而它的输出值域**两头依旧过于平坦**，梯度消失问题仍然存在。为了解决学习缓慢和梯度消失问题，可使用其更加平缓的变体，如log-log、Softsign、Symmetrical Sigmoid等。

![](img\intro\4.png)

### 2.1.3. ReLU函数
1. ReLU函数是目前神经网络里常用的激活函数，由于ReLU函数是**线性特点**使其收敛速度比Sigmoid、Tanh更快，而且没有梯度饱和的情况出现。**计算更加高效**，相比于Sigmoid、Tanh函数，只需要一个阈值就可以得到激活值，不需要对输入归一化来防止达到饱和。

![](img\intro\5.png)

### 2.1.4. Leaky RuLU函数
1. 带泄漏修正线性神经元(Leaky RuLU)的出现是解决"死亡神经元"的问题

![](img\intro\6.png)

### 2.1.5. Maxout函数
1. Maxout是一种分段线性函数，理论上可以拟合任意**凸**函数，与其它激活函数相比，它计算k次权值，从中选择最大值作权值，所以其计算量成k倍增加。当k为2时，可看成是分成两段的线性函数，它的函数公式如下

![](img\intro\7.png)

## 2.2. 损失函数
1. 损失函数评价的是模型对样本拟合度，预测结果与实际值越接近，说明模型的拟合能力越强，对应损失函数的结果就越小；反之，**损失函数的结果越大**。损失函数比较大时，对应的梯度下降比较快。为了计算方便，可以采用欧式距离作损失度量标准，通过最小化实际值与估计值之间的均方误差作为损失函数，即**最小平方误差准则(MSE)**：
![](img\intro\8.png)

2. 其中𝐺(𝑋)是模型根据输入矩阵X输出一个预测向量，预测值𝐺(𝑋)和真值𝑌的欧式距离越大、损失就越大，反之就越小,即求||𝐺 𝑋 − 𝑌||<sup>2</sup>的极小值。如果是批量数据，则将所有数据对应模型结果与其真实值之间的差的平方进行求和。合适的损失函数能够确保深度学习模型更好地收敛，常见的损失函数有Softmax、欧式损失、Sigmoid交叉时损失、Triplet Loss、Moon Loss、 Contrastive Loss等
3. 判断激活函数的选择是否合适，除了MSE以外还有很多

### 2.2.1. Softmax
1. 使用Softmax函数的好处是可以使分类问题的预测结果更加明显，不同类别之间的差距更大。在实际应用中，特别是在Tensorflow中推荐采用交叉熵与Softmax结合作为损失函数，可以避免数值不稳定的情况

### 2.2.2. 交叉熵
1. 目标为二分类问题，分类误差越小，则损失越小，对正负分类计算各自的损失。但是会产生梯度爆炸问题。
    + 不含尖的是这是值。

![](img\intro\9.png)

2. 交叉熵损失函数的用途主要应用在互相排斥的分类任务中
3. 交叉熵也可以用于目标为[0,1]区间的回归问题

![](img\intro\10.png)

### 2.2.3. 均方差损失函数

![](img\intro\11.png)

### 2.2.4. 自定义函数
1. 对于某些候选属性，单独将一些预测值取出或者赋予不同大小的参数。或者合并多个损失函数，实现多目标训练任务，或者在不同的情况下采用不同的损失函数

## 2.3. 学习率(学习步长)
1. 学习率控制每次更新参数的幅度，过高和过低的学习率都可能对模型结果带来不良影响，合适的学习率可以加快模型的训练速度
2. 常见学习率调整方法
    1. 基于经验的手动调整
    2. 固定学习率
    3. 均分分步降低策略
    4. 指数级衰减
    5. 多项式策略
    6. AdaGrad动态调整
    7. AdaDelta自动调整
    8. 动量法动态调整
    9. RMSProp动态调整
    10. 随机梯度下降
    11. Adam自动调整

## 2.4. 过拟合(Over fitting)
1. 过拟合是指模型在训练集上预测效果好，但在测试集上预测效果差
2. 常用的防止过拟合的方法有
    1. 参数范数惩罚
    2. 数据增强
    3. 提前终止
    4. Bagging等集成方法
    5. Dropout
    6. 批正则化

![](img\intro\12.png)

3. 随着学习的深入，如果学习深入过多，有可能造成学习的深入导致过拟合。

### 2.4.1. 过拟合的防止

![](img\intro\13.png)

1. 比如决策树的层数过深,造成过度学习。
2. 我们可以在损失函数上进行处理。
    + 惩罚项是第二项。
    + 将权重减为0，来真正调整神经网络的结构。
3. 又叫L2正则化

漏失
---
![](img\intro\14.png)

1. 不考虑某些节点进行训练，也就意味着可以对一些节点的权重不需要进行考虑了。
    + 不改变本节点的权重

尽早终止
---
![](img\intro\15.png)

1. 理论:损失函数逐渐趋向于0的时候来停止
2. 是对检验样本的损失函数是否下降，下降则终止

动量
---
![](img\intro\16.png)

1. 常规方法容易陷入局部最小值，我们沿着负梯度方向
2. 图解

![](img\intro\17.png)

1. 我们不会直接趋近于负梯度方向，但是我们加上了相应的冲量想来避免局部最小值(跨过去)

# 3. 模型训练中的问题
1. 选择恰当的激活函数
2. 权重初始化
    + 权重的初始化是很重要的，影响迭代的次数和效果，尽量保证权重均匀分布
3. 学习率
4. 使用Dropout正则化
5. 周期/训练迭代次数
6. 训练过程可视
    + 防止陷入局部极小值。

## 3.1. Tensorflow训练
1.  在典型的Tensorflow训练过程中，可以实时将训练参数通过TensorBoard输出 到文件中，并可以在浏览器中输入http://127.0.0.1:6006进行查看。其中 summary_writer的作用是将参数／结构等写入到文件中，详细代码如下
    + TensorBoard就是一个可视化过程。

```python
with tf.Session() as session: 
    init = tf.global_variables_initializer() 
    session.run(init) 
    summary_writer = tf.summary.FileWriter(tensorbardLogPath, session.graph)# 以前是初始化
    for epoch in range(training_epochs):#training_epochs就是循环的次数 
        cost_history = np.empty(shape=[1],dtype=float)# 权重初始化
        for b in range(total_batchs):    
            offset = (b * batch_size) % (train_y.shape[0] - batch_size)
            batch_x = train_x[offset:(offset + batch_size), :, :, :]#x是输入，权重更新结果
            batch_y = train_y[offset:(offset + batch_size), :]#y是类别
            _, c,summary =session.run([optimizer, loss, merged],feed_dict={X: batch_x, Y : batch_y}) 
            cost_history = np.append(cost_history,c)#这个就是训练过程
            summary_writer.add_summary(summary, epoch * training_epochs + b) 
        print "Epoch: ",epoch," Training Loss: ",np.mean(cost_history)," Training Accuracy: ",session.run(accuracy, feed_dict={X: train_x, Y: train_y})#这就是训练结果
    summary_writer.close()
    print "Testing Accuracy:", session.run(accuracy, feed_dict={X: test_x, Y: test_y})
```

2. 结果:每一批次数据训练后会得到损失函数结果，对其进行统计，并计算出当前阶段的准确率，输出到屏幕上，在所有训练结束后再输出整体的准确率结果。如果在训练过程中发现存在异常可以直接中止训练过程，避免浪费时间。

![](img\intro\18.png)

## 3.2. 启用TensorBoard
1. 在命令行中输入以下命令启动TensorBoard,可以查看之前通过 summary_writer写入的参数值`tensorboard --logdir=/Users/lully/Desktop/stock/de/log/`
2. 在浏览器中输入本机和端口(默认为6006)，可以实时查看之前定义并写入的参数和指标

![](img\intro\19.png)

## 3.3. 记录相应变量
1. 其中的变量如何记录呢？以accuracy对应的变化曲线图为例，使用如下代码
```python
with tf.name_scope('train'):
    optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(loss) correct_prediction = tf.equal(tf.argmax(y_,1), tf.argmax(Y,1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) tf.summary.scalar('accuracy', accuracy)
```
2. 其它变量如cross_entropy等的记录方法与此类似，SCALARS面板中主要用于记录诸如准确率、损失和学习率等单个值的变化趋势。此外，还支持对TensorFlow中计算图的结构进行可视化，显示每个节点的计算时间和内存使用情况等。如果要显示内存等信息，可以使用如下代码，主要是在sess.run()中加入options和run_metadata参数，然后就可以在GRAPHS页面中查看对应节点的计算时间或内存信息，使用颜色深浅来表示

## 3.4. 神经网络效果分析
1. 用于分类的模型评价以准确率(Accuracy)、精确率(Precision)、召回率(Recall)、F1分值(F1 Score)为主，辅以ROC、AUC并结合实际应用进行结果评价
2. 如果神经网络用于聚类，数据源并没有进行标记，那么其模型结果的评价按照聚类算法的标准来操作，如RMSSTD、R Square、SRP等
3. 随着机器学习在不同领域中的应用，其评价方式需要与实际业务相结合，通过确定目标要求来定量设计评价标准，例如在目标检测等方面使用平均曲线下面积(mean Average Precision, mAP)指标进行衡量识别准确性 


# 4. 其他阅读连接

<a href = "https://mp.weixin.qq.com/s/wlq19oW9S7CuTRlfgCGYsQ">1. 神经网络通用理论基础</a>
<a href = "https://mp.weixin.qq.com/s/JPhR71zsEAj3Vgy4aKc4bg">2. 神经网络不起作用的理由</a>
<a href = "https://mp.weixin.qq.com/s/H2ccbirv5fCALTByvIEUVw">3. 基于Numpy实现的简单神经网络</a>
<a href = "https://mp.weixin.qq.com/s/3A5GgUNnl6WuOo1ppWmzMQ">4. 学习神经网络的数学原理</a>
<a href = "https://mp.weixin.qq.com/s/K2YcSOorOK_66RTul_uuGQ">5. 100行Python代码，轻松搞定神经网络 </a>

# 5. 应用

## 5.1. 侦测信用卡欺诈
1. 二分类问题可以只有一个输出，也可以两个输出

![](img\appli\1.png")

## 5.2. 股票拐点趋势预测

![](img\appli\2.png)

## 5.3. 手写体识别
1. 0-9的识别

![](img\appli\3.png)

2. 将数字分为十类，0-9，具有10个输出元
3. 利用softmax激活函数。
4. 我们先从黑白图来考虑(不考虑灰度图和彩色图)
    + 我们近似认为覆盖为1，不覆盖为0
    + 也就把输入转化为784位向量
    + 通过实验调整隐层节点的个数，以及隐层数量。
5. 我们一般是有几种类别，我们就有几种输出。

### 5.3.1. 具体实现
1. 数据集是经典的MNIST
2. 加载数据
```python
import tensorflow as tf 
import ssl 
ssl._create_default_https_context = ssl._create_unverified_context 
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("./mnist_data/", one_hot=True)# 下载到本地，并且读入内存
```
3. 定义学习率、迭代次数、批大小、批数量(总样本数除以批大小)等参数，设置输入层大小为784,即将28x28的像素展开为一维行向量(一个输入图片784个值)。第一层和第二层神经元数量均为256，输出层的分类类别为0〜9的数字，即10个类别。
```python
#设置参数的值
learning_rate = 0.005
training_epochs = 20 
batch_size = 100 #每100个处理一次
batch_count = int(mnist.train.num_examples/batch_size) 
n_hidden_1 = 256 
n_hidden_2 = 256 
_input = 784 
n_classes = 10 # (0-9 数字) 
X = tf.placeholder("float", [None, n_input]) 
Y = tf.placeholder("float", [None, n_classes])
```
4. 使用tf.random_normal()生成模型权重值参数矩阵和偏置值参数，并将其分别存储于weights和biases变量中，并定义多层感知机的神经网络模型。代码如下 
```python
weights = { 
    #对于权重的初始化
    'weight1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),
    'weight2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),
    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))
} 
biases = { 
    #对于隐层的初始化
    'bias1': tf.Variable(tf.random_normal([n_hidden_1])),
    'bias2': tf.Variable(tf.random_normal([n_hidden_2])),
    'out': tf.Variable(tf.random_normal([n_classes]))
} 
def multilayer_perceptron_model(x):
    # 多层感知机的模型     
    layer_1 = tf.add(tf.matmul(x, weights['weight1']), biases['bias1'])
    layer_2 = tf.add(tf.matmul(layer_1, weights['weight2']), biases['bias2'])
    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']
    return out_layer
```
5. 使用输入变量X初始化模型，定义损失函数为交叉熵，采用梯度下降法作为优化器(除此之外还可选MomentumOptimizer、AdagradOptimizer、AdamOptimizer等，见注释部分)，并对模型中tf.placeholder定义的各参数 初始化，代码如下
```python
logits = multilayer_perceptron_model(X) 
loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))#以上是进行训练
optimizer = tf.train.GradientDescentOptimizer(learning_rate)# 做优化的，使用梯度下降法。
#optimizer = tf.train.MomentumOptimizer(learning_rate,0.2)
#optimizer = tf.train.AdagradOptimizer(learning_rate)
#optimizer = tf.train.AdamOptimizer(learning_rate)
train_op = optimizer.minimize(loss_op)
init = tf.global_variables_initializer()#参数初始化
```
6. 将训练集样本输入模型进行训练，并计算每个批次的平均损失，在每次迭代时输出模型的平均损失，代码如下
```python
with tf.Session() as sess:
    sess.run(init)#训练epoch几次
    for epoch in range(training_epochs): 
        avg_cost = 0.
        for i in range(batch_count):    
            train_x, train_y =  mnist.train.next_batch(batch_size)
            _, c = sess.run([train_op, loss_op], feed_dict={X: train_x, Y: train_y})#真正跑起来
            avg_cost += c / batch_count 
        print("Epoch:", '%02d' % (epoch+1), "avg cost={:.6f}".format(avg_cost))
```
7. 评估:模型训练完成，使用测试集样本对其评估，并计算其精确率，代码如下
```python
pred = tf.nn.softmax(logits) 
# Apply softmax to logits
correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))
print("Accuracy:", accuracy.eval({X: mnist.test.images, Y: mnist.test.labels}))
```
